{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8347346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:154: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:155: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:156: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:157: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:158: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:159: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:154: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:155: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:156: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:157: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:158: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:159: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:10: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  wpm_path = 'D:\\DirSpec\\data\\WPM_spectra.xlsx'\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:154: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_txt = pd.read_csv(txt_buoy_file, sep='\\s+', skiprows=[1], na_values=[\"MM\",'999.0'])\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:155: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_data_spec = pd.read_csv(data_spec_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:156: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_swdir = pd.read_csv(swdir_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:157: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_swr1 = pd.read_csv(swr1_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:158: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_swdir2 = pd.read_csv(swdir2_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_19364\\643128138.py:159: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df_swr2 = pd.read_csv(swr2_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import sys\n",
    "\n",
    "buoys = [46026, 41009]\n",
    "url = r'https://www.ndbc.noaa.gov/data/realtime2/'\n",
    "wpm_path = 'D:\\DirSpec\\data\\WPM_spectra.xlsx'\n",
    "\n",
    "def create_tables(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS buoys (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                buoy_id TEXT UNIQUE NOT NULL,\n",
    "                name TEXT,\n",
    "                lat DOUBLE PRECISION,\n",
    "                lon DOUBLE PRECISION,\n",
    "                depth DOUBLE PRECISION\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS time_steps (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                buoy_id INTEGER REFERENCES buoys(id),\n",
    "                timestamp TIMESTAMPTZ NOT NULL,\n",
    "\n",
    "                -- Observational metadata\n",
    "                station_id TEXT,                  -- NDBC ID (e.g., '46026')\n",
    "                WDIR INTEGER,                     -- Wind direction (degrees)\n",
    "                WSPD DOUBLE PRECISION,            -- Wind speed (m/s or knots)\n",
    "                GST  DOUBLE PRECISION,            -- Wind gust (m/s or knots)\n",
    "                WVHT DOUBLE PRECISION,            -- Significant wave height [m]\n",
    "                DPD  DOUBLE PRECISION,            -- Dominant period [s]\n",
    "                APD  DOUBLE PRECISION,            -- Average period [s]\n",
    "                MWD  DOUBLE PRECISION,            -- Mean wave direction (from) [deg]\n",
    "                PRES DOUBLE PRECISION,            -- Atmospheric pressure [hPa]\n",
    "                ATMP DOUBLE PRECISION,            -- Air temp [°C]\n",
    "                WTMP DOUBLE PRECISION,            -- Water temp [°C]\n",
    "                DEWP DOUBLE PRECISION,            -- Dew point [°C]\n",
    "                VIS  DOUBLE PRECISION,            -- Visibility [nmi]\n",
    "                PTDY DOUBLE PRECISION,            -- Pressure tendency [hPa]\n",
    "                TIDE DOUBLE PRECISION,            -- Tide level [ft or m]\n",
    "\n",
    "                -- Derived spectral parameters\n",
    "                m0   DOUBLE PRECISION,            -- Spectral moment 0\n",
    "                hm0  DOUBLE PRECISION,            -- Significant wave height from spectrum\n",
    "                m_1  DOUBLE PRECISION,            -- Spectral moment 1\n",
    "                Te   DOUBLE PRECISION,            -- Energy period\n",
    "                P    DOUBLE PRECISION,            -- Wave power [kW/m]\n",
    "                    \n",
    "                spectra_ingested BOOLEAN DEFAULT FALSE, -- Marker to record that spectral data was ingested for the timestep\n",
    "\n",
    "            UNIQUE (buoy_id, timestamp)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS spectra (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                time_step_id INTEGER REFERENCES time_steps(id),\n",
    "                frequency DOUBLE PRECISION,\n",
    "                direction INTEGER,\n",
    "                dir_dist DOUBLE PRECISION,\n",
    "                energy_density DOUBLE PRECISION,\n",
    "                spectra_ingested BOOLEAN DEFAULT FALSE,\n",
    "                UNIQUE (time_step_id, frequency, direction)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "def insert_time_steps(df_time_steps, cur):\n",
    "    for _, row in df_time_steps.iterrows():\n",
    "        # Get buoy ID (assumes station_id already inserted in buoys)\n",
    "        cur.execute(\"SELECT id FROM buoys WHERE station_id = %s\", (row['station_id'],))\n",
    "        buoy_id = cur.fetchone()\n",
    "        if buoy_id:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO time_steps (\n",
    "                    buoy_id, timestamp, WDIR, WSPD, GST, WVHT, DPD, APD, MWD, PRES,\n",
    "                    ATMP, WTMP, DEWP, VIS, PTDY, TIDE, m0, hm0, m_1, Te, P\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (buoy_id, timestamp) DO NOTHING;\n",
    "            \"\"\", (\n",
    "                buoy_id[0], row['datetime'],\n",
    "                safe_val(row.get('WDIR')), safe_val(row.get('WSPD')), safe_val(row.get('GST')), safe_val(row.get('WVHT')),\n",
    "                safe_val(row.get('DPD')), safe_val(row.get('APD')), safe_val(row.get('MWD')), safe_val(row.get('PRES')),\n",
    "                safe_val(row.get('ATMP')), safe_val(row.get('WTMP')), safe_val(row.get('DEWP')), safe_val(row.get('VIS')),\n",
    "                safe_val(row.get('PTDY')), safe_val(row.get('TIDE')), safe_val(row.get('m0')), safe_val(row.get('hm0')),\n",
    "                safe_val(row.get('m_1')), safe_val(row.get('Te')), safe_val(row.get('P'))\n",
    "            ))\n",
    "\n",
    "def get_unprocessed_timesteps(cur, station_id):\n",
    "    # Step 1: get buoy_id from station_id\n",
    "    cur.execute(\"SELECT id FROM buoys WHERE station_id = %s\", (station_id,))\n",
    "    buoy = cur.fetchone()\n",
    "    if not buoy:\n",
    "        return []\n",
    "\n",
    "    buoy_id = buoy[0]\n",
    "\n",
    "    # Step 2: get time steps where spectra_ingested is false\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT timestamp\n",
    "        FROM time_steps\n",
    "        WHERE buoy_id = %s AND (spectra_ingested = FALSE OR spectra_ingested IS NULL)\n",
    "        ORDER BY timestamp\n",
    "    \"\"\", (buoy_id,))\n",
    "\n",
    "    return cur.fetchall()  # returns list of (timestamp)         \n",
    "\n",
    "def get_time_step_id(cur, station_id, dt_utc):\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT ts.id\n",
    "        FROM time_steps ts\n",
    "        JOIN buoys b ON ts.buoy_id = b.id\n",
    "        WHERE b.station_id = %s AND ts.timestamp = %s\n",
    "    \"\"\", (station_id, dt_utc))\n",
    "    \n",
    "    result = cur.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def datetime_dfs(x,buoy_id):\n",
    "    new_columns = ['year','month','day','hour','minute']\n",
    "    x.rename(columns=dict(zip(x.columns[0:5], new_columns)),inplace=True)\n",
    "    x.insert(0,'datetime',pd.to_datetime(x[['year', 'month', 'day', 'hour', 'minute']],utc=True))\n",
    "    x.insert(0,'station_id',buoy_id)\n",
    "    x.drop(['year', 'month', 'day', 'hour', 'minute'], axis='columns',inplace=True)\n",
    "    return x\n",
    "\n",
    "def safe_val(val):\n",
    "    return None if pd.isna(val) else val\n",
    "\n",
    "def met_to_math_dir(angle_deg):\n",
    "    return np.deg2rad((270 - angle_deg) % 360)\n",
    "\n",
    "def get_buoy_data():    \n",
    "    for buoy_id in buoys:  \n",
    "        # create the buoy filepath to request from\n",
    "        txt_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.txt\"\n",
    "        data_spec_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.data_spec\"\n",
    "        swdir_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.swdir\"\n",
    "        swr1_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.swr1\"\n",
    "        swdir2_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.swdir2\"\n",
    "        swr2_buoy_file = f\"https://www.ndbc.noaa.gov/data/realtime2/{buoy_id}.swr2\"\n",
    "\n",
    "        # load to dataframes\n",
    "        df_txt = pd.read_csv(txt_buoy_file, sep='\\s+', skiprows=[1], na_values=[\"MM\",'999.0'])\n",
    "        df_data_spec = pd.read_csv(data_spec_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
    "        df_swdir = pd.read_csv(swdir_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
    "        df_swr1 = pd.read_csv(swr1_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
    "        df_swdir2 = pd.read_csv(swdir2_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
    "        df_swr2 = pd.read_csv(swr2_buoy_file, sep='\\s+', skiprows=[0], na_values=[\"MM\",'999.0'], header=None)\n",
    "\n",
    "        # create datetime columns for dataframes (needed for matching timesteps across dataframes)\n",
    "        df_list = [df_txt,df_data_spec,df_swdir,df_swr1,df_swdir2,df_swr2]\n",
    "        for df in df_list:\n",
    "            df = datetime_dfs(df,buoy_id)\n",
    "\n",
    "        # remove frequency identifiers\n",
    "        df_data_spec.drop(range(7,98,2),axis='columns',inplace=True)        \n",
    "        df_swdir.drop(range(6,97,2),axis='columns',inplace=True)\n",
    "        df_swr1.drop(range(6,97,2),axis='columns',inplace=True)\n",
    "        df_swdir2.drop(range(6,97,2),axis='columns',inplace=True)\n",
    "        df_swr2.drop(range(6,97,2),axis='columns',inplace=True)\n",
    "\n",
    "        # rename frequency columns with integers for simplicity\n",
    "        column_list = ['station_id','datetime','sep_freq'] + list(range(1,47))\n",
    "        df_data_spec = df_data_spec.set_axis(column_list,axis=1)\n",
    "        # repeat for the rest without sep_freq column\n",
    "        column_list = ['station_id','datetime'] + list(range(1,47))\n",
    "        df_swdir = df_swdir.set_axis(column_list,axis=1)\n",
    "        df_swdir2 = df_swdir2.set_axis(column_list,axis=1)\n",
    "        df_swr1 = df_swr1.set_axis(column_list,axis=1)\n",
    "        df_swr2 = df_swr2.set_axis(column_list,axis=1)\n",
    "\n",
    "        # remove unneeded timesteps from df_txt\n",
    "        df_txt = df_txt[df_txt['datetime'].isin(df_data_spec['datetime'])]\n",
    "        df_txt = df_txt.reset_index(drop=True)\n",
    "\n",
    "        # remove unmatching timesteps from spec dataframes (no df_txt match)\n",
    "        df_data_spec = df_data_spec[df_data_spec['datetime'].isin(df_txt['datetime'])]\n",
    "        df_swdir = df_swdir[df_swdir['datetime'].isin(df_txt['datetime'])]\n",
    "        df_swdir2 = df_swdir2[df_swdir2['datetime'].isin(df_txt['datetime'])]\n",
    "        df_swr1 = df_swr1[df_swr1['datetime'].isin(df_txt['datetime'])]\n",
    "        df_swr2 = df_swr2[df_swr2['datetime'].isin(df_txt['datetime'])]\n",
    "\n",
    "        df_data_spec = df_data_spec.reset_index(drop=True)\n",
    "        df_swdir = df_swdir.reset_index(drop=True)\n",
    "        df_swdir2 = df_swdir2.reset_index(drop=True)\n",
    "        df_swr1 = df_swr1.reset_index(drop=True)\n",
    "        df_swr2 = df_swr2.reset_index(drop=True)\n",
    "\n",
    "        # do calculations for specific timestep -> df_txt is timestep output table\n",
    "        calc = df_data_spec.iloc[:,3:50] * bandwidths\n",
    "        # zeroth moment and Hm0\n",
    "        df_txt['m0'] = calc.sum(axis=1)\n",
    "        df_txt['hm0'] = np.sqrt(df_txt['m0'])*4\n",
    "        calc2 = calc / center_freqs\n",
    "        # 1st moment, energy period, and wave power\n",
    "        df_txt['m_1'] = calc2.sum(axis=1)\n",
    "        df_txt['Te'] = df_txt['m_1'] / df_txt['m0']\n",
    "        df_txt['P'] = (1025 * 9.81**2 * df_txt['hm0']**2 * df_txt['Te']) / (64 * np.pi * 1000)\n",
    "\n",
    "        # convert the buoy ids to strings\n",
    "        df_txt['station_id'] = df_txt['station_id'].astype(str)\n",
    "\n",
    "        # write the new timesteps for the buoy to the timestep table\n",
    "        cur = conn.cursor()\n",
    "        insert_time_steps(df_txt,cur)\n",
    "        conn.commit()\n",
    "\n",
    "        # check for spectrum ingested flag across timesteps\n",
    "        unprocessed_timesteps = get_unprocessed_timesteps(cur, str(buoy_id))\n",
    "        if not unprocessed_timesteps:\n",
    "            # move on to next buoy if the list is empty\n",
    "            continue\n",
    "        flat = [row[0] for row in unprocessed_timesteps if row and row[0] is not None]\n",
    "        dt_index = pd.to_datetime(flat, utc=True)\n",
    "\n",
    "        # select timesteps from the current data where flag isn't set to true\n",
    "        df_data_spec = df_data_spec[df_data_spec['datetime'].isin(dt_index)].reset_index(drop=True)\n",
    "        df_swr1 = df_swr1[df_swr1['datetime'].isin(dt_index)].reset_index(drop=True)\n",
    "        df_swr2 = df_swr2[df_swr2['datetime'].isin(dt_index)].reset_index(drop=True)\n",
    "        df_swdir = df_swdir[df_swdir['datetime'].isin(dt_index)].reset_index(drop=True)\n",
    "        df_swdir2 = df_swdir2[df_swdir2['datetime'].isin(dt_index)].reset_index(drop=True)\n",
    "\n",
    "        # loop through each timestep needed (i = timestep index)\n",
    "        # this builds the spectra table with concatentation\n",
    "        for i,spec_row in df_data_spec.iterrows():\n",
    "            # get the timestep rows for all tables needed\n",
    "            swdir_row = df_swdir.iloc[i,:]\n",
    "            swdir2_row = df_swdir2.iloc[i,:]\n",
    "            swr1_row = df_swr1.iloc[i,:]\n",
    "            swr2_row = df_swr2.iloc[i,:]\n",
    "\n",
    "            # check that all files have the timestep\n",
    "            if spec_row['datetime'] == swdir_row['datetime'] and spec_row['datetime'] == swdir2_row['datetime'] and spec_row['datetime'] == swr1_row['datetime'] and spec_row['datetime'] == swr2_row['datetime']:\n",
    "                pass\n",
    "            else:\n",
    "                print('Datetime mismatch')\n",
    "                sys.exit()\n",
    "                break\n",
    "\n",
    "            # save the datetime object for reference later\n",
    "            datetime_obj = spec_row['datetime']\n",
    "            \n",
    "            # drop the unneeded rows for calculations\n",
    "            spec_row = spec_row.iloc[3:]\n",
    "            swdir_row = swdir_row.iloc[2:]\n",
    "            swdir2_row = swdir2_row.iloc[2:]\n",
    "            swr1_row = swr1_row.iloc[2:]\n",
    "            swr2_row = swr2_row.iloc[2:]\n",
    "            \n",
    "            # prepare for vectorized calculation\n",
    "            alpha1 = pd.to_numeric(swdir_row, errors='coerce')\n",
    "            alpha1 = np.where(~np.isnan(alpha1), met_to_math_dir(alpha1), np.nan)\n",
    "            alpha1.astype(float)\n",
    "            alpha2 = pd.to_numeric(swdir2_row, errors='coerce')\n",
    "            alpha2 = np.where(~np.isnan(alpha2), met_to_math_dir(alpha2), np.nan)\n",
    "            alpha2.astype(float)\n",
    "\n",
    "            r1 = pd.to_numeric(swr1_row,errors='coerce')\n",
    "            r1 = np.array(r1)\n",
    "            r2 = pd.to_numeric(swr2_row, errors='coerce')\n",
    "            r2 = np.array(r2)\n",
    "\n",
    "            Ef = pd.to_numeric(spec_row, errors='coerce')\n",
    "            Ef = np.array(Ef)\n",
    "\n",
    "            alpha1_grid = alpha1[:,None]\n",
    "            alpha2_grid = alpha2[:, None]\n",
    "            E = Ef[:, None]\n",
    "\n",
    "            D = (1 / (2 * np.pi)) * (\n",
    "                (1 + 2 * r1[:, None] * np.cos(theta_grid - alpha1_grid))\n",
    "                + (2 * r2[:, None] * np.cos(2 * (theta_grid - alpha2_grid))\n",
    "                ))\n",
    "            \n",
    "            # remove negatives from D output\n",
    "            D = np.maximum(D, 0)\n",
    "            \n",
    "            row_sums = np.sum(D, axis=1, keepdims=True) * delta_theta_rad\n",
    "            row_sums[row_sums == 0] = 1\n",
    "            D_normalized = D / row_sums\n",
    "            #check = np.sum(D_normalized, axis=1, keepdims=True) * delta_theta_rad\n",
    "            #print(check)\n",
    "\n",
    "            S = D_normalized * E\n",
    "\n",
    "            # get the timestep id from the timesteps table\n",
    "            timestep_id = get_time_step_id(cur, str(buoy_id), datetime_obj)\n",
    "\n",
    "            # organize for exporting to postgres table\n",
    "            records_param = []\n",
    "            records_dir = []\n",
    "            for m, f in enumerate(freqs):\n",
    "                # these values are recorded to every row for this frequency bin\n",
    "                a_1 = float(alpha1[m]) if not np.isnan(alpha1[m]) else None\n",
    "                a_2 = float(alpha2[m]) if not np.isnan(alpha2[m]) else None\n",
    "                r_1 = float(r1[m]) if not np.isnan(r1[m]) else None\n",
    "                r_2 = float(r2[m]) if not np.isnan(r2[m]) else None\n",
    "                energy_density = float(E[m, 0])\n",
    "                records_param.append((int(timestep_id), float(f), a_1, a_2, r_1, r_2, float(energy_density)))\n",
    "\n",
    "            # write the spectral data to the spec table\n",
    "            spectra_parameters_insert_query = \"\"\"\n",
    "                INSERT INTO spectra_parameters (time_step_id, frequency, alpha1, alpha2, r1, r2, energy_density)\n",
    "                VALUES %s\n",
    "                ON CONFLICT (time_step_id, frequency) DO NOTHING\n",
    "            \"\"\"\n",
    "            psycopg2.extras.execute_values(cur, spectra_parameters_insert_query, records_param, page_size=100)\n",
    "\n",
    "            for m, f in enumerate(freqs):\n",
    "                for n, theta in enumerate(directional_pnts):\n",
    "                    spreading = float(D[m, n])\n",
    "                    records_dir.append((int(timestep_id), float(f), int(theta), float(spreading)))\n",
    "\n",
    "            direction_insert_query = \"\"\"\n",
    "                INSERT INTO spectra_directional (\n",
    "                    time_step_id, frequency, direction, spreading\n",
    "                ) VALUES %s\n",
    "                ON CONFLICT (time_step_id, frequency, direction) DO NOTHING\n",
    "            \"\"\"\n",
    "            psycopg2.extras.execute_values(cur, direction_insert_query, records_dir, page_size=500)\n",
    "\n",
    "            conn.commit()\n",
    "            # update flag\n",
    "            cur.execute(\"\"\"\n",
    "                UPDATE time_steps\n",
    "                SET spectra_ingested = TRUE\n",
    "                WHERE id = %s\n",
    "            \"\"\", (timestep_id,))\n",
    "            conn.commit()\n",
    "                  \n",
    "# run table setup function to ensure tables exist\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"Jacob\",\n",
    "    password=\"\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "create_tables(conn)\n",
    "\n",
    "# pull in the wpm freqs and bin sizes\n",
    "wpm_data = pd.read_excel(wpm_path,header=None,skiprows=1)\n",
    "center_freqs = pd.Series(wpm_data.iloc[:,1])\n",
    "freqs = np.array(center_freqs)\n",
    "bandwidths = pd.Series(wpm_data.iloc[:,2])\n",
    "\n",
    "# create 72 directional points to iterate over for NOAA buoys\n",
    "directional_pnts = np.arange(0,360,5)\n",
    "theta_grid = directional_pnts[None, :]\n",
    "delta_theta_deg = 5\n",
    "delta_theta_rad = np.deg2rad(delta_theta_deg)\n",
    "\n",
    "# pull down and process the NOAA buoy data\n",
    "get_buoy_data()\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
